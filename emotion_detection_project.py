# -*- coding: utf-8 -*-
"""emotion_detection_project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k4NWpjytrYw6cAEBNOsA2gzuy1SqDXlG

**Emotion_Detection**

**importing libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import numpy as np
from glob import glob
import cv2
import random
import os
# %matplotlib inline

from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv2D
from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras.utils import plot_model

from IPython.display import SVG,Image
import tensorflow as tf
print("numpy version : ", np.__version__)
print("tensorflow version : ", tf.__version__)

images = glob("train/**/**")
for i in range(9):
    image = random.choice(images)
    plt.figure(figsize = (12,12))
    plt.subplot(331 + i)
    plt.imshow(cv2.imread(image))
    plt.axis('off')



"""**preparaing data for training**"""

img_size = 48
batch_size = 64
epochs = 30
learning_rate = 0.001
datagen_train = ImageDataGenerator(
    rescale = 1.0/255,
    rotation_range = 15,
    width_shift_range = 0.2,
    height_shift_range = 0.2,
    zoom_range = 0.2,
    horizontal_flip = True,
    fill_mode = "nearest"
)
train_generator = datagen_train.flow_from_directory("train/",target_size = (img_size,img_size), color_mode = "grayscale", batch_size = batch_size, class_mode = 'categorical', shuffle = True)

datagen_validation = ImageDataGenerator(
    rescale = 1.0/255
)
validation_generator = datagen_validation.flow_from_directory("test/",target_size = (img_size,img_size), color_mode = "grayscale", batch_size = batch_size, class_mode = 'categorical', shuffle = False)

"""**Defining Model**"""

def Convolution(input_tensor, filters, kernel_size):
    x = Conv2D(filters = filters, kernel_size = kernel_size, padding = "same")(input_tensor)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(pool_size = (2,2))(x)
    x = Dropout(0.3)(x)

    return x

def Dense_f(input_tensor,nodes):
    x = Dense(nodes)(input_tensor)
    x = BatchNormalization()(x)
    x = Activation('relu')(x)
    x = Dropout(0.3)(x)

    return x

def model_fer(input_shape):
    inputs = Input(input_shape)
    conv_1 = Convolution(inputs, 32, (3,3))
    conv_2 = Convolution(inputs, 64, (5,5))
    conv_3 = Convolution(inputs, 128, (3,3))

    flatten = Flatten()(conv_3)

    dense_1 = Dense_f(flatten,256)
    output = Dense(8,activation = "softmax")(dense_1)
    model = Model(inputs = [inputs], outputs = [output])

    model.compile(loss = ['categorical_crossentropy'], optimizer = Adam(learning_rate = learning_rate), metrics = ['accuracy'])
    return model

model = model_fer((img_size,img_size,2))
model.summary()

"""**Initialize Model**"""

checkpoint = ModelCheckpoint(
    "model_weights.h5",
    monitor = "val_accuracy",
    save_best_only = True,
    mode = "max",
    verbose = 1
)
reduce_lr = ReduceLROnPlateau(
    monitor = "val_loss",
    factor = 0.5,
    patience = 3,
    verbose = 1,
    min_lr = 1e-6
)
callbacks = [checkpoint, reduce_lr]
steps_per_epoch = int(train_generator.n/train_generator.batch_size)
validation_steps = int(validation_generator.n/validation_generator.batch_size)

"""**Training Model**"""

history = model.fit(
    train_generator,
    steps_per_epoch = steps_per_epoch,
    epochs = epochs,
    validation_data = validation_generator,
    validation_steps = validation_steps,
    callbacks = callbacks)

model.evaluate(validation_generator)

"""**Plotting Loss**"""

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title(['Model loss'])
plt.legend(['Train', 'Validation'], loc = 'upper left')
plt.subplot_adjust(top = 1.0, bottom = 0.0, right = 0.95, left = 0.0, hspace = 0.25,  wspace = 0.35)

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title(['Model Accuracy'])
plt.legend(['Train', 'Validation'], loc = 'upper left')
plt.subplot_adjust(top = 1.0, bottom = 0.0, right = 0.95, left = 0.0, hspace = 0.25, wspace = 0.35)

"""**SAVING MODEL**"""

model_json = model.to_json()
with open("model_a.json", "w") as json_file:
    json_file.write(model_json)